{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Fresh 68k PBMCs (Donor A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares the 68K PBMC dataset for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "from scipy.io import mmread\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines paths and loads the 68k PBMC dataset with annotations. It transposes the DataFrame, because the input data for Geneformer should have the cells located in the columns. After transposing, the index column contains the column name as a value, which is why the index should be resetted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "file_path_sparse = \"/home/cog/nlandzaat/rep_learning_sc_foundation/raw/PBMC/sparse_matrix_pmbc68kdata.txt\"\n",
    "\n",
    "# load dataset\n",
    "with open(file_path_sparse) as matrix_file:\n",
    "    matrix_sparse = mmread(matrix_file)\n",
    "\n",
    "df = pd.DataFrame.sparse.from_spmatrix(matrix_sparse)\n",
    "\n",
    "# load annotations\n",
    "gene_ID_names = pd.read_csv(\"/home/cog/nlandzaat/rep_learning_sc_foundation/raw/PBMC/annotatie.csv\")\n",
    "df.columns = gene_ID_names[\"ENSEMBL_IDS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/17309981/ipykernel_2496279/977535884.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_transposed[\"ENSEMBL_IDS\"] = df_transposed.index\n"
     ]
    }
   ],
   "source": [
    "# transpose DataFrame\n",
    "df_transposed = df.T\n",
    "\n",
    "# reset the index\n",
    "df_transposed[\"ENSEMBL_IDS\"] = df_transposed.index\n",
    "df_transposed = df_transposed.reset_index(drop=True)\n",
    "\n",
    "# move \"ENSEMBL_IDS\" column to the first position\n",
    "df_transposed = df_transposed[[\"ENSEMBL_IDS\"] + [col for col in df_transposed.columns if col != \"ENSEMBL_IDS\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map de gene names to the Ensembl IDs, this is necessary because the gene names need to be specified in order to use the Geneformer model. Not all Ensembl IDs are recognized, resulting in NaN in the Gene_names column. These genes are dropped from the dataset. The missing Ensembl IDs are listed in missing_ids_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/17309981/ipykernel_2496279/2608749983.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_transposed[\"Gene_names\"] = df_transposed[\"ENSEMBL_IDS\"].map(mapping_dict)\n"
     ]
    }
   ],
   "source": [
    "# load the file with Ensembl ID to gene name mapping\n",
    "mapping_df = pd.read_csv(\"/home/cog/nlandzaat/rep_learning_sc_foundation/raw/PBMC/mart_export.txt\", delimiter=\",\")\n",
    "\n",
    "# create a mapping dictionary from \"Gene stable ID\" to \"Gene name\"\n",
    "mapping_dict = mapping_df.set_index(\"Gene stable ID\")[\"Gene name\"].to_dict()\n",
    "\n",
    "# map the gene names to df_transposed based on the ensemble IDs\n",
    "df_transposed[\"Gene_names\"] = df_transposed[\"ENSEMBL_IDS\"].map(mapping_dict)\n",
    "\n",
    "# these Ensembl IDs do not have a matching gene name\n",
    "missing_ids = df_transposed[~df_transposed[\"ENSEMBL_IDS\"].isin(mapping_df[\"Gene stable ID\"])][\"ENSEMBL_IDS\"]\n",
    "missing_ids_list = missing_ids.to_list()\n",
    "\n",
    "# remove rows (genes) with NaN\n",
    "df_cleaned = df_transposed.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for foundation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geneformer requires gene names, we dropped the Ensembl IDs and only kept the gene names. Dropping the Ensembl IDs is not necessary to leave them out of the models' calculation, since the models ask for specification of the layer where the raw counts are stored.\n",
    "\n",
    "The following code creates an AnnData object (adata_GF) from the DataFrame (df_gf) containing gene expression data. The DataFrame is transposed to have samples as rows and genes as columns, aligning with the format expected by the AnnData object. The AnnData object is initialized with the transposed expression data (X), where each row represents a sample (cell) and each column represents a gene. Additionally, empty DataFrame objects are created for observations (obs) and variables (var). The code then generates cell names for each sample in the observations DataFrame, using the format \"cell 1\", \"cell 2\", and so on. Additionally, the raw counts are stored in the layer \"counts\", which is necessary for extracting the raw counts by the foundation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Ensembl IDs\n",
    "df_gf = df_cleaned.drop(\"ENSEMBL_IDS\", axis=1)\n",
    "df_gf.set_index(\"Gene_names\", inplace=True)\n",
    "df_gf.index.name = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/compgen/users/nlandzaat/Software/anaconda3/envs/project_env_test/lib/python3.9/site-packages/anndata/_core/anndata.py:1899: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "# create an AnnData object \n",
    "adata_GF = anndata.AnnData(X=df_gf.values.T, var=pd.DataFrame(index=df_gf.index), obs=pd.DataFrame(index=df_gf.columns))\n",
    "\n",
    "# create cell names in obs\n",
    "adata_GF.obs[\"cell_names\"] = [\"PBMC\" for i in range (len(adata_GF.obs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a layer named \"counts\" and store the raw counts in it\n",
    "adata_GF.layers[\"counts\"] = df_gf.values.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AnnData object is prepared for use by the foundation model, it is stored to an h5ad file so that it can be accessed later. Before converting the AnnData file, modifications are necessary. The indeces of the variables and observations attributes are converted to strings. The h5ad file is saved to the specified file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# modify and store the AnnData object\n",
    "file_path = \"/home/cog/nlandzaat/rep_learning_sc_foundation/raw/PBMC/adata_GF.h5ad\"\n",
    "\n",
    "adata_GF.var.index = adata_GF.var.index.astype(str)\n",
    "adata_GF.obs.index = adata_GF.obs.index.astype(str)\n",
    "# save AnnData to h5ad file\n",
    "adata_GF.write_h5ad(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for PCA and UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a DataFrame (df_cleaned) where genes are represented as rows and samples as columns. To align with the requirements of PCA and UMAP, we transpose the DataFrame to have samples as rows and genes as columns. We then drop the \"Gene_names\" column and move the Ensembl IDs to the index, in order to exclude them from calculations. Next, we convert the DataFrame to numeric values using pd.to_numeric to ensure consistency and compatibility with PCA and UMAP. As the dataset is large, we convert it to a sparse matrix for memory efficiency. Finally, we create an AnnData object using the sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move ensemble ids to index \n",
    "df_cleaned = df_cleaned.set_index(df_cleaned.columns[0])\n",
    "\n",
    "# transpose data frame \n",
    "df_pca = df_cleaned.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Gene_names column\n",
    "row_to_drop = [\"Gene_names\"]\n",
    "df_pca = df_pca.drop(row_to_drop, axis=0)\n",
    "\n",
    "# convert to numeric\n",
    "df_pca = df_pca.apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the entire DataFrame to a sparse matrix\n",
    "sparse_matrix = csr_matrix(df_pca.values)\n",
    "\n",
    "# convert the DataFrame to an AnnData object \n",
    "adata = sc.AnnData(X=sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save adata\n",
    "\n",
    "# specify the file path \n",
    "adata_file_path = \"/home/cog/nlandzaat/rep_learning_sc_foundation/raw/PBMC/adata_PBMC_PCA_UMAP.h5ad\"\n",
    "\n",
    "# write adata to the specified file path\n",
    "adata.write(adata_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
